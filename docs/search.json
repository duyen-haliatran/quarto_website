[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Duyen_website",
    "section": "",
    "text": "Welcome to my website"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Duyen’s Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List\n\n\n\n\n\n\nDuyen Tran\n\n\nMay 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nDuyen Tran\n\n\nMay 2, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "A Replication of Karlan and List",
    "section": "",
    "text": "Code\n# import sys;\n# print(sys.executable)"
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "A Replication of Karlan and List",
    "section": "Sub-Header",
    "text": "Sub-Header"
  },
  {
    "objectID": "projects/project1/index.html#description",
    "href": "projects/project1/index.html#description",
    "title": "Project 1",
    "section": "",
    "text": "/usr/local/bin/python3\n\n\n\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns"
  },
  {
    "objectID": "projects/project1/index.html#data",
    "href": "projects/project1/index.html#data",
    "title": "A Replication of Karlan and List",
    "section": "Data",
    "text": "Data\n\nDescription\nThe data set contains 50,083 observations and 51 variables. The key variables are as follows:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB"
  },
  {
    "objectID": "projects/project1/index.html#balance-test",
    "href": "projects/project1/index.html#balance-test",
    "title": "A Replication of Karlan and List",
    "section": "Balance Test",
    "text": "Balance Test\n\nNumber of Months since last donation\nTest months since last donation to see if the treatment and control group are statistically different at the 95% confidence level\n\nT-test\n\\[H_0: \\mu_{months\\;treatment} = \\mu_{months\\;control} \\] \\[H_a: \\mu_{months\\;treatment} \\neq \\mu_{months\\;control}  \\]\nThe t-value formula is given by:\n\\[\nt_{\\text{value}} = \\frac{\\bar{x}_{\\text{1}} - \\bar{x}_{\\text{2}}}{\\sqrt{\\frac{s_{\\text{1}}^2}{n_{\\text{1}}} + \\frac{s_{\\text{2}}^2}{n_{\\text{2}}}}}\n\\]\nI know there are serverals library that can automatically calculate the t values for us, but as structure, we will define the t_value using the formula in the class slides\n\n\nCode\ndef t_value(treatment, control):\n    # calculate x_bar\n    x_treatment = treatment.mean()\n    x_control = control.mean()\n    #calculate std\n    s_treatment = treatment.std()\n    s_control = control.std()\n    \n    n_treatment = len(treatment)\n    n_control = len(control)\n    \n    t_value = (x_treatment - x_control)/np.sqrt((s_treatment**2/n_treatment) + (s_control**2/n_control))\n    return t_value\n\n\n\n\nCode\nt_value_months = t_value(months_treatment, months_control)\nprint(f\"T_values is {round(t_value_months, 4)}\")\n\n\nT_values is 0.1195\n\n\nThe formula of degree of freedom is:\n\\[\ndf = \\frac{(n_1 - 1)(n_2 - 1)}{(n_2 - 1)(\\frac{\\frac{s_1^2}{n_1}}{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}})^2 + (n_1 - 1)(1 - \\frac{\\frac{s_1^2}{n_1}}{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}})^2}\n\\]\nDefine a fuction to find degree of freedom\n\n\nCode\ndef dof(treatment, control):\n    # calculate x_bar\n    x_treatment = treatment.mean()\n    x_control = control.mean()\n    #calculate std\n    s_treatment = treatment.std()\n    s_control = control.std()\n    \n    n_treatment = len(treatment)\n    n_control = len(control)\n    \n    # Find the degree of freedom\n\n    #Assign the complex formula in the denorminator to b\n    b = (s_treatment**2/n_treatment)/(s_treatment**2/n_treatment+s_control**2/n_control)\n    \n    numerator = (n_treatment-1)*(n_control-1)\n    \n    denominator = (n_control-1)*(b**2) + (n_treatment-1)*((1-b)**2)\n    \n    degree_of_freedom = numerator/denominator\n    return degree_of_freedom\n\n\n\n\nCode\ndof_months = dof(months_treatment, months_control)\nprint(f\"Degree of freedom is {round(dof_months, 2)}\")\n\n\nDegree of freedom is 33394.14\n\n\n\n\nCode\n# Find p-value\np_value = (1-t.cdf(t_value_months, dof_months))*2\nprint(f\"P_value is {round(p_value, 3)}\")\n\n\nP_value is 0.905\n\n\nThe independent t-test on the ‘mrm2’ variable (months since last donation) between the treatment and control groups yields a t-statistic of approximately 0.1195 and a p-value of 0.905.\nGiven the high p-value (much greater than the alpha level of 0.05), we fail to reject the null hypothesis, which suggests that there is no statistically significant difference in the mean number of months since the last donation between the treatment and control groups.\n\n\nLinear Regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data,\n    rvar = 'mrm2',\n    evar = 'treatment'\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n12.998\n0.094\n138.979\n0.000\n***\n\n\n1\ntreatment\n0.014\n0.115\n0.119\n0.905\n\n\n\n\n\n\n\n\n\nThe linear regression results are as follows:\n\nThe coefficient for treatment is approximately 0.014 with a standard error of about 0.115.\nThe t-statistic for the treatment coefficient is 0.119, and the p-value is 0.905.\n\nThese results are consistent with the independent t-test findings. The p-value in both analyses is much larger than the alpha level of 0.05, indicating no statistical significance. The t-statistic from the regression is the same as the t-statistic from the t-test, and the p-value confirms that there is no significant difference in the number of months since last donation (mrm2) between the treatment and control groups at the 95% confidence level.\n\n\n\nHighest previous contribution\nTest the highest previous contribution to see if the treatment and control group are statistically different at 95% confidence level\n\\[H_0: \\mu_{contribution\\;treatment} = \\mu_{contribution\\;control} \\] \\[H_a: \\mu_{contribution\\;treatment} \\neq \\mu_{contribution\\;control}  \\]\n\n\nCode\nhpa_treatment = data.loc[data['treatment'] == 1,'hpa']\nhpa_control = data.loc[data['treatment'] == 0,'hpa']\n\n# Apply the t_values function that we defined above\nt_value_hpa = t_value(hpa_treatment, hpa_control)\nprint(f\"T_value is {round(t_value_hpa, 4)}\")\n\n\nT_value is 0.9704\n\n\n\n\nCode\n#Apply the degree of freedom funcion that we defined above\ndof_hpa = dof(hpa_treatment, hpa_control)\nprint(f\"Degree of freedom is {round(dof_hpa, 2)}\")\n\n\nDegree of freedom is 35913.89\n\n\n\n\nCode\n# Find p-value\np_value = (1-t.cdf(t_value_hpa, dof_hpa))*2\nprint(f\"P_value is {round(p_value, 3)}\")\n\n\nP_value is 0.332\n\n\nThe independent t-test on the ‘hpa’ variable (highest previous contribution) between the treatment and control groups yields a t-statistic of approximately 0.9704 and a p-value of 0.332.\nGiven the high p-value (much greater than the alpha level of 0.05), we fail to reject the null hypothesis, which suggests that there is no statistically significant difference in the mean number of the highest previous contribution between the treatment and control groups.\n\nLinear Regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data,\n    rvar = 'hpa',\n    evar = 'treatment'\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n58.960\n0.551\n107.005\n0.000\n***\n\n\n1\ntreatment\n0.637\n0.675\n0.944\n0.345\n\n\n\n\n\n\n\n\n\nThe linear regression results are as follows:\n\nThe coefficient for treatment is approximately 0.637 with a standard error of about 0.675.\nThe t-statistic for the treatment coefficient is 0.944, and the p-value is 0.345.\n\nThese results are consistent with the independent t-test findings. The p-value in both analyses is much larger than the alpha level of 0.05, indicating no statistical significance. The t-statistic from the regression is the same as the t-statistic from the t-test, and the p-value confirms that there is no significant difference in the number of highest previous contribution of treatment and control groups at the 95% confidence level.\n\n\n\nPercent already donated in 2005\nTest the percent already donated in 2005 to see if the treatment and control group are statistically different at 95% confidence level\n\\[H_0: \\mu_{percent\\;treatment} = \\mu_{percent\\;control} \\] \\[H_a: \\mu_{percent\\;treatment} \\neq \\mu_{percent\\;control}  \\]\n\nT-test\n\n\nCode\ndormant_treatment = data.loc[data['treatment'] == 1,'dormant']\ndormant_control = data.loc[data['treatment'] == 0,'dormant']\n\n# Apply the t_values function that we defined above\nt_value_dormant = t_value(dormant_treatment, dormant_control)\nprint(f\"T_value is {round(t_value_dormant, 3)}\")\n\n\nT_value is 0.174\n\n\n\n\nCode\n#Apply the degree of freedom funcion that we defined above\ndof_dormant = dof(dormant_treatment, dormant_control)\nprint(f\"Degree of freedom is {round(dof_dormant, 2)}\")\n\n\nDegree of freedom is 33362.05\n\n\n\n\nCode\n# Find p-value\np_value = (1-t.cdf(t_value_dormant, dof_dormant))*2\nprint(f\"P_value is {round(p_value, 3)}\")\n\n\nP_value is 0.862\n\n\nThe independent t-test on the ‘dormant’ variable (Percent already donated in 2005) between the treatment and control groups yields a t-statistic of approximately 0.174 and a p-value of 0.862.\nGiven the high p-value (much greater than the alpha level of 0.05), we fail to reject the null hypothesis, which suggests that there is no statistically significant difference in the mean percent already donated in 2005 between the treatment and control groups.\n\n\nLinear Regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data,\n    rvar = 'dormant',\n    evar = 'treatment'\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n0.523\n0.004\n135.247\n0.000\n***\n\n\n1\ntreatment\n0.001\n0.005\n0.174\n0.862\n\n\n\n\n\n\n\n\n\nThe linear regression results are as follows:\n\nThe coefficient for treatment is approximately 0.001 with a standard error of about 0.005.\nThe t-statistic for the treatment coefficient is 0.171, and the p-value is 0.862.\n\nThese results are consistent with the independent t-test findings. The p-value in both analyses is much larger than the alpha level of 0.05, indicating no statistical significance. The t-statistic from the regression is the same as the t-statistic from the t-test, and the p-value confirms that there is no significant difference in the percent already donated in 2005 of treatment and control groups at the 95% confidence level.\n\n\n\nProportion of white people within the zipcode\n\\[H_0: \\mu_{pwhite\\;treatment} = \\mu_{pwhite\\;control} \\] \\[H_a: \\mu_{pwhite\\;treatment} \\neq \\mu_{pwhite\\;control}  \\]\n\nT-test\n\n\nCode\npwhite_treatment = data.loc[data['treatment'] == 1,'pwhite']\npwhite_control = data.loc[data['treatment'] == 0,'pwhite']\n\n# Apply the t_values function that we defined above\nt_value_pwhite = t_value(pwhite_treatment, pwhite_control)\nprint(f\"T_value is {round(t_value_pwhite, 3)}\")\n\n\nT_value is -0.57\n\n\n\n\nCode\n#Apply the degree of freedom funcion that we defined above\ndof_pwhite = dof(pwhite_treatment, pwhite_control)\nprint(f\"Degree of freedom is {round(dof_pwhite, 2)}\")\n\n\nDegree of freedom is 33185.24\n\n\n\n\nCode\n# Find p-value\np_value = (t.cdf(t_value_pwhite, dof_pwhite))*2\nprint(f\"P_value is {round(p_value, 3)}\")\n\n\nP_value is 0.569\n\n\nThe independent t-test on the ‘pwhite’ variable (proportion of white people within zipcode) between the treatment and control groups yields a t-statistic of approximately -0.57 and a p-value of 0.569.\nGiven the high p-value (much greater than the alpha level of 0.05), we fail to reject the null hypothesis, which suggests that there is no statistically significant difference in the proportion of white people within zipcode between the treatment and control groups.\n\n\nLinear Regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data,\n    rvar = 'pwhite',\n    evar = 'treatment'\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n0.820\n0.001\n616.281\n0.000\n***\n\n\n1\ntreatment\n-0.001\n0.002\n-0.560\n0.575\n\n\n\n\n\n\n\n\n\nThe linear regression results are as follows:\n\nThe coefficient for treatment is approximately - 0.001 with a standard error of about 0.002.\nThe t-statistic for the treatment coefficient is -0.560, and the p-value is 0.575.\n\nThese results are consistent with the independent t-test findings. The p-value in both analyses is much larger than the alpha level of 0.05, indicating no statistical significance. The t-statistic from the regression is the same as the t-statistic from the t-test, and the p-value confirms that there is no significant difference in the proportion of white people in the zipcode of treatment and control groups at the 95% confidence level.\nSidenote: I can’t replicate the results same as table 1 in the paper. Mean for pwhite is:\n\n\nCode\navg_white_treatment = pwhite_treatment.mean()\navg_white_control = pwhite_control.mean()\nprint(f\"The avg pwhite of treatment group is {round(avg_white_treatment,2)}\")\n\nprint(f\"The avg pwhite of treatment group is {round(avg_white_control,2)}\")\n\n\nThe avg pwhite of treatment group is 0.8199999928474426\nThe avg pwhite of treatment group is 0.8199999928474426\n\n\nWhereas the results in table 1 are 0.831 and 0.830, respectively"
  },
  {
    "objectID": "projects/project1/index.html#charitable-contribution-made",
    "href": "projects/project1/index.html#charitable-contribution-made",
    "title": "A Replication of Karlan and List",
    "section": "Charitable Contribution Made",
    "text": "Charitable Contribution Made\n\nProportion of donation\n\n\nCode\ngave_treatment = data[data['treatment'] == 1]['gave'].mean()\ngave_control = data[data['treatment'] == 0]['gave'].mean()\n\nproportions = [gave_treatment, gave_control]\ngroup_labels = ['Treatment', 'Control']\n\n# Create the bar plot\nplt.bar(group_labels, proportions, color=['blue', 'orange'])\n\n# Add labels and title\nplt.ylabel('Proportion who donated')\nplt.title('Proportion of Donations by Group')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nAs visual, we can interpret that the treatment group had a higher response rate for making donations than the control group, which implies that the treatment might have effective in encouraging donations. However, we have to do further statistical analysis to assess the reliability of this observed difference\n\n\nT-test\nFirst of all, let’s check the similarity between our data and Panel A in table 2A\n\n\nCode\ndonated_treatment = data[data['treatment'] == 1]['gave']\ndonated_control = data[data['treatment'] == 0]['gave']\n\nx_bar_treatment = donated_treatment.mean()\nx_bar_control = donated_control.mean()\nprint(f'The response rate of treatment group panel A is {round(x_bar_treatment, 3)}')\nprint(f'The response rate of treatment group panel A is {round(x_bar_control, 3)}')\n\n\nThe response rate of treatment group panel A is 0.022\nThe response rate of treatment group panel A is 0.018\n\n\n\n\nCode\n# Apply the t_values function that we defined above\nt_value_donated = t_value(donated_treatment, donated_control)\nprint(f\"T_value is {round(t_value_donated, 3)}\")\n\n\nT_value is 3.209\n\n\n\n\nCode\n#Apply the degree of freedom funcion that we defined above\ndof_donated = dof(donated_treatment, donated_control)\nprint(f\"Degree of freedom is {round(dof_donated, 2)}\")\n\n\nDegree of freedom is 36576.84\n\n\n\n\nCode\n# Find p-value\np_value = (1 - t.cdf(t_value_donated, dof_donated))*2\nprint(f\"P_value is {round(p_value, 3)}\")\n\n\nP_value is 0.001\n\n\nThe independent t-test on the ‘gave’ variable between the treatment and control groups yields a t-statistic of approximately 3.209 and a p-value of 0.001.\nThis p-value is less than the alpha level of 0.05, indicating that there is a statistically significant difference between the treatment and control groups in terms of the proportion of participants who made a donation.\n\n\nLinear Regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data,\n    rvar = 'gave',\n    evar = 'treatment'\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n0.018\n0.001\n16.225\n0.000\n***\n\n\n1\ntreatment\n0.004\n0.001\n3.101\n0.002\n**\n\n\n\n\n\n\n\n\nThe linear regression results are as follows:\n\nThe coefficient for treatment is approximately 0.004 with a standard error of about 0.001.\nThe t-statistic for the treatment coefficient is 3.1, and the p-value is 0.002.\n\nThis p-value is also less than the alpha level of 0.05, suggesting that the treatment has a statistically significant effect on the likelihood of making a donation. The positive coefficient indicates that being in the treatment group is associated with higher odds of giving a donation compared to the control group.\nBoth the t-test and logistic regression demonstrate that there is a significant difference in the donation behavior between the treatment and control groups, with the treatment group showing a higher propensity to give\nIn the context of the experiment, the statistical significance of the treatment group’s coefficient implies that the treatment has a positive effect on the likelihood that someone will donate. This insight into human behavior suggests that the strategy employed to encourage donations in the treatment group was effective in increasing donation rates.\nIn other words, if the experiment involved sending out letters asking for donations, and the treatment group received letters with a special message or offer not given to the control group, we could interpret these results to mean that the special message or offer motivated more people to donate. The important takeaway here is that small changes in how we ask for donations can have a significant impact on people’s willingness to contribute to a cause. This aligns with the findings presented in Table 2A, Panel A, which we aimed to confirm with our analysis.\n\n\nProbit Regression\n\n\nCode\nX_linear = sm.add_constant(data['treatment'])  # Add a constant to the independent variable\ny_linear = data['gave'] \n# Fit the Probit regression model using 'treatment' as the predictor and 'gave' as the binary outcome\nprobit_model = sm.Probit(y_linear, X_linear).fit()\n\n# Get the summary of the Probit regression results\nprobit_summary = probit_model.summary()\n# Extract only the regression results table\nprobit_results_table = probit_summary.tables[1]\n\n# To display or print out the table\nprint(probit_results_table)\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nThe Probit regression results are as follows:\nThe coefficient for treatment is 0.0868, with a standard error of 0.028. The z-statistic for the treatment coefficient is 3.113, and the p-value is 0.002.\nThe coeficient and standard errors do not match between the Table 3 on the paper and the Probit Regression, it matches to the Linear regression results instead\nHowever, p value of both models are the same, which is smaller than 0.05, sugessts that treatment had a positive impact on the probability of giving, which supports the same notion: the treatment apprears to have effectively encouraged more people to donate"
  },
  {
    "objectID": "projects/project1/index.html#differences-between-match-rates",
    "href": "projects/project1/index.html#differences-between-match-rates",
    "title": "A Replication of Karlan and List",
    "section": "Differences between Match Rates",
    "text": "Differences between Match Rates\nThe Z score formula of proportion is \\[\nz = \\frac{p_a - p_b}{\\sqrt{\\frac{p_a(1 - p_a)}{n_a} + \\frac{p_b(1 - p_b)}{n_b}}}\n\\]\nSame as the t_value function above, let’s define z_score function\n\n\nCode\ndef z_score(data1, data2, full_data):\n    p1 = data1.mean()\n    p2 = data2.mean()\n\n    numerator = p1-p2\n    denominator = np.sqrt((p1*(1-p1))/len(data1) + (p2*(1-p2)/len(data2)))\n\n    z_score = numerator / denominator\n    return z_score\n\n\nDouble check the similarity response rate to Table 2 Panel A\n\n\nCode\ngave_ratio1 = data[data['ratio'] == 1]['gave']\ngave_control = data[data['ratio'] == \"Control\"]['gave']\ngave_ratio2 = data[data['ratio'] == 2]['gave']\ngave_ratio3 = data[data['ratio'] == 3]['gave']\n\nprint(f'Response rate of 1:1 matching is {round(gave_ratio1.mean(), 3)}')\nprint(f'Response rate of 2:1 matching is {round(gave_ratio2.mean(), 3)}')\nprint(f'Response rate of 3:1 matching is {round(gave_ratio3.mean(), 3)}')\n\n\nResponse rate of 1:1 matching is 0.021\nResponse rate of 2:1 matching is 0.023\nResponse rate of 3:1 matching is 0.023\n\n\n\nControl vs 1:1 match\n\\[H_0: p_{Control} = p_{1:1\\;Ratio}\\] \\[H_a: p_{Control} \\neq p_{1:1\\;Ratio}\\]\n\nZ-test\n\n\nCode\n# Apply the function that we defined above\nz_score_ratio1 = z_score(gave_ratio1, gave_control, data)\nprint(f'Z score is {round(z_score_ratio1, 3)}')\n\n\nZ score is 1.705\n\n\n\n\nCode\n# find p value\np_value = norm.sf(z_score_ratio1)*2\nprint(f\"p_value is {round(p_value, 3)}\")\n\n\np_value is 0.088\n\n\nZ-Value: A z-value of 1.705 indicates that the effect of being in the 1:1 match ratio group is 1.705 standard deviations away from the mean effect of being in the control group. This suggests a positive direction of influence towards increasing the likelihood of donation.\nP-Value: The p-value of 0.088, though close, is above the conventional threshold of 0.05 (95% confidence level). This suggests that while there is some evidence to suggest an effect, it does not meet the usual criteria for statistical significance. Hence, we would not reject the null hypothesis at the 5% significance level, which states there is no difference in donation likelihood between the 1:1 match and control groups\n\n\n\nControl vs 2:1 match\n\\[H_0: p_{Control} = p_{2:1\\;Ratio}\\] \\[H_a: p_{Control} \\neq p_{2:1\\;Ratio}\\]\n\nZ-test\n\n\nCode\nz_score_ratio2 = z_score(gave_ratio2, gave_control, data)\nprint(f'Z score is {round(z_score_ratio2, 4)}')\n\n\nZ score is 2.7397\n\n\n\n\nCode\n# find p value\np_value = norm.sf(z_score_ratio2)*2\nprint(f\"p_value is {round(p_value, 3)}\")\n\n\np_value is 0.006\n\n\nZ-Value: A z-value of 2.739 indicates that the effect of being in the 2:1 match ratio group is 2.739 standard deviations away from the mean effect of being in the control group. This represents a stronger and more distinct effect compared to the control, suggesting a significant positive influence on donation likelihood.\nP-Value: The p-value of 0.006 is well below the conventional threshold of 0.05, indicating strong statistical significance. This suggests that we can reject the null hypothesis, or there is significant difference in the likelihood of making a donation between the 2:1 match ratio and control groups.\n\n\n\nControl vs 3:1 match\n\\[H_0: p_{Control} = p_{3:1\\;Ratio}\\] \\[H_a: p_{Control} \\neq p_{3:1\\;Ratio}\\]\n\nZ-test\n\n\nCode\nz_score_ratio3 = z_score(gave_ratio3, gave_control, data)\nprint(f'Z score is {round(z_score_ratio3, 3)}')\n\n\nZ score is 2.793\n\n\n\n\nCode\n# find p value\np_value = norm.sf(z_score_ratio3)*2\nprint(f\"p_value is {round(p_value, 3)}\")\n\n\np_value is 0.005\n\n\nZ-Value: A z-value of 2.793 indicates that the effect of being in the 3:1 match ratio group is nearly 2.8 standard deviations away from the mean effect of being in the control group. This shows a strong positive impact of the 3:1 matching offer on the likelihood of making a donation.\nP-Value: The p-value of 0.0052 clearly falls below the typical significance threshold of 0.05, affirming that this result is statistically significant. This strongly suggests rejecting the null hypothesis, or there is significant difference in donation likelihood between the 3:1 match ratio and the control groups.\nAbout the figures suggest\n\nSupport the statement: If the match thresholds for different ratios were relatively low and thus easilu attainable, and the data still shows a significant different between higher ratios and the control, it supports the notion that increasing the match ratio is an effectve strategy. It suggests that the actual ratio, rather than the ease of achieving a match, motivates donors\nContradiction of the statement: The significant effects effects observed at higher match ratios contradict any implication the match ratios do not influence donor behavior. It shows that higher ratios can indeed motivate more donations\n\n\n\n\nRegression on ratio1, ratio2, ratio3\nFirst of all, create a new ratio1 variable\n\n\nCode\ndata['ratio1'] = rsm.ifelse(data.ratio == 1, 1, 0)\n\n\n\nLinear regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data,\n    rvar = 'gave',\n    evar = ['ratio1', 'ratio2', 'ratio3']\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n0.018\n0.001\n16.225\n0.000\n***\n\n\n1\nratio1\n0.003\n0.002\n1.661\n0.097\n.\n\n\n2\nratio2\n0.005\n0.002\n2.744\n0.006\n**\n\n\n3\nratio3\n0.005\n0.002\n2.802\n0.005\n**\n\n\n\n\n\n\n\n\nThe linear regression results are as follows:\nratio1 represent 1:1 matching:\n\nCoefficient: 0.003: suggesting that ratio increases the probability of making a donation by 0.3% points\np_value = 0.097\n\nAt the 95% confidence level, the coefficient for 1:1 match ratio is not statistically significant because p_value is greater than 0.05, which means we are less confident that 1:1 match ratio has a real effect on the donation probability in the population\nratio2 represent 2:1 matching:\n\nCoefficient: 0.005, indicates a 0.5% point increase in the probability of making a donation\nP-value: 0.006\n\nThe coefficient for the 2:1 match ratio is statistically significant at the 95% confidence level, as the p-value is well below 0.05, which means we can quite confident that the 2:1 match ratio has a positive effect on the probability of donating\nratio3 represent 3:1 matching:\n\nCoefficient: 0.005, also indicates a 0.5% point increase in the probability of making a donation\nP-value: 0.005\n\nSimilarly, the coefficient for the 3:1 match ratio is statistically significant at the 95% confidence level.\nStatistical Precision\nThe ‘std.error’ column shows the standard error of each coefficient, which is a measure of the precision of the coefficient estimate. Smaller standard errors indicate more precise estimates. In this table, the standard errors for the treatment levels are the same (0.002), suggesting similar levels of precision across these estimates.\nThe results indicate that only the 2:1 and 3:1 match ratios significantly increase the likelihood of donations compared to the control group at the 95% confidence level. The effects of these higher match ratios are robust, suggesting that they are effective strategies for increasing donation rates.\nThe 1:1 match ratio, while showing a positive effect, does not reach the threshold for statistical significance at this confidence level. This implies that while there might be a slight increase in donation likelihood with a 1:1 match, the evidence is not strong enough to conclusively state this at the 95% confidence level.\n\n\nResponse rate difference\n\n\nCode\nrr_1_1 = data[data['ratio1'] == 1]['gave'].mean()\nrr_2_1 = data[data['ratio2'] == 1]['gave'].mean()\nrr_3_1 = data[data['ratio3'] == 1]['gave'].mean()\n\nrr_diff_11_vs_21 = rr_2_1 - rr_1_1\nrr_diff_21_vs_31 = rr_3_1 - rr_2_1\n\nprint(f'The response rate difference between the 1:1 and 2:1 match ratios {round(rr_diff_11_vs_21, 3)}')\nprint(f'The response rate difference between the 2:1 and 3:1 match ratios {round(rr_diff_21_vs_31, 3)}')\n\n\nThe response rate difference between the 1:1 and 2:1 match ratios 0.002\nThe response rate difference between the 2:1 and 3:1 match ratios 0.0\n\n\nRecall the linear regression result above:\n\n\nCode\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n0.018\n0.001\n16.225\n0.000\n***\n\n\n1\nratio1\n0.003\n0.002\n1.661\n0.097\n.\n\n\n2\nratio2\n0.005\n0.002\n2.744\n0.006\n**\n\n\n3\nratio3\n0.005\n0.002\n2.802\n0.005\n**\n\n\n\n\n\n\n\n\n\n\nCode\ncoef_ratio1 = 0.003\ncoef_ratio2 = 0.005\ncoef_ratio3 = 0.005\n\ncoef_11_vs_21 = coef_ratio2 - coef_ratio1\ncoef_21_vs_31 = coef_ratio3 - coef_ratio2\n\nprint(f'The response rate difference between the 1:1 and 2:1 match ratios from regression is {round(coef_11_vs_21, 3)}')\nprint(f'The response rate difference between the 2:1 and 3:1 match ratios from regression is {round(coef_21_vs_31, 3)}')\n\n\nThe response rate difference between the 1:1 and 2:1 match ratios from regression is 0.002\nThe response rate difference between the 2:1 and 3:1 match ratios from regression is 0.0\n\n\n1:1 vs 2:1 : The very small difference (0.002) suggests only a marginal improvement in the response rate from the 1:1 and 2:1 match ratio. This indicates that while the 2:1 match ratio might be slightly more effective than 1:1, the difference is minimal\n2:1 vs 3:1 The zero difference suggest that there is no additional benefit in increasing the match ratio from 2:1 to 3:1 regarding the likelihood of donations. This suggests diminishing returns when the match ratio increase beyond 2:1\nThese findings imply that while increasing the match ratio from 1:1 to 2:1 might offer a slight increase in donation likelihood, increasing it further to 3:1 does not yield additional benefits. This could be crucial for organizations in deciding how aggressively to pursue higher matching ratios in their fundraising strategies. The minimal differences suggest that other factors may be more critical in influencing donation behavior than merely adjusting the match ratio."
  },
  {
    "objectID": "projects/project1/index.html#size-of-charitable-contribution",
    "href": "projects/project1/index.html#size-of-charitable-contribution",
    "title": "A Replication of Karlan and List",
    "section": "Size of Charitable Contribution",
    "text": "Size of Charitable Contribution\n\\[H_0: \\mu_{amount\\;treatment} = \\mu_{amount\\;control} \\] \\[H_a: \\mu_{amount\\;treatment} \\neq \\mu_{amount\\;control}  \\]\n\n\nCode\namount_treatment = data.loc[data['treatment'] == 1,'amount']\namount_control = data.loc[data['treatment'] == 0,'amount']\n\n# Apply the t_values function that we defined above\nt_value_amount = t_value(amount_treatment, amount_control)\nprint(f\"T_value is {t_value_amount}\")\n\n\nT_value is 1.9182617883567805\n\n\n\n\nCode\n#Apply the degree of freedom funcion that we defined above\ndof_amount = dof(amount_treatment, amount_control)\nprint(f\"Degree of freedom is {dof_amount}\")\n\n\nDegree of freedom is 36216.06015374612\n\n\n\n\nCode\n# Find p-value\np_value = (1-t.cdf(t_value_amount, dof_amount))*2\nprint(f\"P_value is {p_value}\")\n\n\nP_value is 0.055085678607487365\n\n\nThe t-test results show a t-statistic of approximately 1.918 with a p-value of 0.055. This p-value is slightly above the conventional threshold of 0.05, indicating that the difference in average donation amounts between the treatment and control groups is not statistically significant at the 5% level. However, the p-value is close to the threshold, suggesting a potential trend where the treatment group might have higher donation amounts than the control group, though this difference isn’t strong enough to be considered statistically significant.\n\nLinear Regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data,\n    rvar = 'amount',\n    evar = 'treatment'\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n0.813\n0.067\n12.063\n0.000\n***\n\n\n1\ntreatment\n0.154\n0.083\n1.861\n0.063\n.\n\n\n\n\n\n\n\n\nLinear Regression Results:\nIntercept: 0.8133\nThis suggests that the average donation amount for the control group is approximately 0.813 units.\nCoefficient for Treatment: 0.154\nThis indicates that being in the treatment group is associated with an increase in the donation amount by approximately 0.154 units compared to the control group.\nP-Value for Treatment: 0.063\nThe p-value is slightly above the conventional threshold of 0.05, indicating that the effect of treatment on donation amount is not statistically significant at the 5% level. However, it’s close, suggesting a potential positive impact of the treatment on donation amounts.\nOverall Interpretation: Both the t-test and the linear regression suggest that the treatment might have a slight positive effect on donation amounts, but this effect does not reach statistical significance. This could imply that while the treatment potentially influences donations positively, the effect is not large or consistent enough across the sample to conclude definitively about its effectiveness. It’s also possible that other variables not considered here could be influencing the donations, and including those in the model could potentially change these results.\n\n\nLimit only those who made a donation:\n\n\nCode\ndata_donated = data[data['amount'] &gt; 0]\n\n\n\nT-Test\n\n\nCode\ndonated_treatment = data_donated.loc[data_donated['treatment'] == 1,'amount']\ndonated_control = data_donated.loc[data_donated['treatment'] == 0,'amount']\n\n# Apply the t_values function that we defined above\nt_value_donated = t_value(donated_treatment, donated_control)\nprint(f\"T_value is {t_value_donated}\")\n\n\nT_value is -0.5846089783693985\n\n\n\n\nCode\n#Apply the degree of freedom funcion that we defined above\ndof_donated = dof(donated_treatment, donated_control)\nprint(f\"Degree of freedom is {dof_donated}\")\n\n\nDegree of freedom is 557.4599283248195\n\n\n\n\nCode\n# Find p-value\np_value = t.cdf(t_value_donated, dof_donated)*2\nprint(f\"P_value is {p_value}\")\n\n\nP_value is 0.5590471873269819\n\n\nThe t-statistic of -0.5846 suggests a lower average donation amount in the treatment group compared to the control group among donors, though the difference is minor.\nThe p-value of 0.559 indicates that this difference is not statistically significant. This means we do not have sufficient evidence to conclude that the treatment affects donation amounts among those who donate.\n\n\nLinear Regression\n\n\nCode\nlr = rsm.model.regress(\n    data = data_donated,\n    rvar = 'amount',\n    evar = 'treatment'\n)\nlr.coef.round(3)\n\n\n\n\n\n\n\n\n\n\nindex\ncoefficient\nstd.error\nt.value\np.value\n\n\n\n\n\n0\nIntercept\n45.540\n2.423\n18.792\n0.000\n***\n\n\n1\ntreatment\n-1.668\n2.872\n-0.581\n0.561\n\n\n\n\n\n\n\n\n\nTreatment Coefficient: The coefficient for the treatment group is approximately -1.67 with a standard error of about 2.87. This suggests that, on average, the treatment group donated about 1.67 units less than the control group among those who donated.\nStatistical Significance: P-value for the Treatment: The p-value for the treatment effect is 0.561, which is not statistically significant. This implies that there is no strong evidence to suggest that the treatment effect differs from zero in the population of donors.\nThe negatice coefficient for the treatment group suggests that the treatment potentially lead to a decrease in the amount donated compared to the control group among those who donated. However, the lack of statistical significance (p-value &gt; 0.05) means we can not confidently assert that this treatment effect is different from zero in the broader donor population.\nCausal Interpretation:\nWhether the treatment coefficient can be interpreted causally depends on how the treatment was assigned. If the treatment was randomly assigned to participants, then the coefficient could potentially have a causal interpretation. Random assignment would help control for both observed and unobserved confounding variables, allowing us to attribute differences in outcomes directly to the treatment effect.\nWhat Did We Learn?\nThe analysis indicates that among those who chose to donate, the treatment did not significantly increase donation amounts. In fact, the point estimate suggests a slight decrease in donations, but this result is not statistically significant. This finding helps understand the treatment’s impact specifically on the subset of the population that decides to donate, complementing the broader analysis which includes non-donors.\n\n\nPlots\n\n\nCode\n# Prepare the plots for treatment and control groups who made donations\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n\n# Plot for Treatment Group\naxes[0].hist(donated_treatment, bins=30, color='blue', alpha=0.7)\naxes[0].axvline(donated_treatment.mean(), color='red', linestyle='dashed', linewidth=1)\naxes[0].set_title('Treatment Group Donation Amounts')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].text(donated_treatment.mean(), max(axes[0].get_ylim()) * 0.5, f'Average: {donated_treatment.mean():.2f}', color='red')\n\n# Plot for Control Group\naxes[1].hist(donated_control, bins=30, color='green', alpha=0.7)\naxes[1].axvline(donated_control.mean(), color='red', linestyle='dashed', linewidth=1)\naxes[1].set_title('Control Group Donation Amounts')\naxes[1].set_xlabel('Donation Amount')\naxes[1].set_ylabel('Frequency')\naxes[1].text(donated_control.mean(), max(axes[1].get_ylim()) * 0.5, f'Average: {donated_control.mean():.2f}', color='red')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nTreatment Group Donation Amounts:\nThe majority of donations are concentrated in the lower range of amounts, with the frequency decreasing as the amount increases.\nThere’s a significant frequency at the lowest amount, indicating that many donations are of a small value.\nThe average donation amount in the treatment group is indicated by a vertical dotted red line and is annotated as $43.87.\nControl Group Donation Amounts:\nSimilar to the treatment group, most donations are of a lower amount, with frequency tapering off for higher donation amounts.\nThe distribution of donations appears slightly more spread out than the treatment group, with some higher amounts being more frequent compared to the treatment group.\nThe average donation amount for the control group is slightly higher than the treatment group, marked by a vertical dotted red line, at $45.54.\nInterpretation:\n\nThe control group has a slightly higher average donation amount compared to the treatment group.\nBoth histograms appear right-skewed, which is common in financial data since a large number of small donations are often accompanied by a smaller number of much larger donations"
  },
  {
    "objectID": "projects/project1/index.html#simulation-experiment",
    "href": "projects/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\n\nLaw of Large Numbers\n\n\nCode\n# Define probabilities for Bernoulli distributions\np_control = 0.018  # Probability for control group\np_treatment = 0.022  # Probability for treatment group\n\n# Simulate 100,000 draws for the control group\ncontrol_samples = np.random.binomial(1, p_control, 100000)\n\n# Simulate 10,000 draws for the treatment group\ntreatment_samples = np.random.binomial(1, p_treatment, 10000)\n\n# Calculate differences for each of the first 10,000 elements in the control sample (to match treatment sample size)\ndifferences = treatment_samples - control_samples[:10000]\n\n# Calculate cumulative averages of differences\ncumulative_averages = np.cumsum(differences) / (np.arange(10000) + 1)\n\n# Plot the cumulative averages of the differences\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_averages, label='Cumulative Average of Differences', color='blue')\nplt.axhline(y=(p_treatment - p_control), color='red', linestyle='dashed', label='True Difference (0.022 - 0.018)')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Difference')\nplt.title('Cumulative Average of Differences Between Treatment and Control')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nExplaination of the plot The plot above illustrates the cumulative average of differences in donation behavior between treatment group (with a charitable donation match) and the control group (without a match), based on simulated data.\n\nBlue line: This represents the cumulative average of the difference between the donation outcomes of indiividual in the treatmetn and control groups across 10,000 simulated trial. The differences are calculated for each trial as the outcome of the treatment minus the outcome of the control.\nRed dashed line: This line marks the true difference in means between the probabilities of making a donation in the treatment and control groups, which is p_treatment - p_control = 0.022 - 0.018 = 0.004.\n\nObservations from the plot\nThe blue line, or the cumulative average of differences, fluctuates initially but starts to stabilize and approach the red dashed line as the number of trials increases. This behavior exemplifies the Law of Large Numbers, which states that as the number of trials increases, the sample average will converge to the expected value (in this case, the true difference in means).\nThe plot confirms that with a sufficient number of trials, the cumulative average of the differences in donation behavior between the treatment and control groups approaches the true difference in means. This simulation reinforces our understanding of statistical concepts like the Law of Large Numbers and provides a visual affirmation that with enough data, our estimates can reliably approximate true population parameters. This also supports the validity of using such statistical methods to evaluate the effects of interventions like charitable donation matches\n\n\nCentral Limit Theorem\n\n\nCode\n# Define sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5), sharey=True)\n\n# Simulate the process and plot the histograms\nfor i, sample_size in enumerate(sample_sizes):\n    # Simulate drawing samples and calculating the means 1000 times\n    sample_means = np.array([np.mean(np.random.binomial(1, p_treatment, sample_size) - \n                                     np.random.binomial(1, p_control, sample_size)) \n                             for _ in range(1000)])\n    \n    # Plot the histogram\n    axes[i].hist(sample_means, bins=30, orientation='horizontal', color='blue', alpha=0.6, edgecolor='black')\n    \n    # Calculate the mean and standard deviation for the normal distribution curve\n    mean_of_sample_means = np.mean(sample_means)\n    std_dev_of_sample_means = np.std(sample_means)\n\n    # Generate values for the normal distribution curve\n    curve_x = np.linspace(mean_of_sample_means - 3 * std_dev_of_sample_means, \n                          mean_of_sample_means + 3 * std_dev_of_sample_means, 100)\n    curve_y = (1 / (std_dev_of_sample_means * np.sqrt(2 * np.pi)) *\n               np.exp(-(curve_x - mean_of_sample_means) ** 2 / (2 * std_dev_of_sample_means ** 2)))\n    \n    # Scale the curve y to match the histogram scale\n    curve_y_scaled = curve_y * max(np.histogram(sample_means, bins=30)[0]) / max(curve_y)\n    \n    # Draw the normal distribution curve as a red line\n    axes[i].plot(curve_y_scaled, curve_x, '-')\n\n    # Add a red dashed line at the true difference\n    axes[i].axhline(y=0.004, color='red', linestyle='dashed', linewidth=2)\n\n    # Set titles and labels\n    axes[i].set_title(f'Sample Size {sample_size}')\n    axes[i].set_xlabel('Frequency' if i == len(sample_sizes) - 1 else '')  # Only add xlabel to the last subplot\n    axes[i].set_ylabel('Average Difference' if i == 0 else '')  # Only add ylabel to the first subplot\n\n# Adjust layout for better fit\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nAs we can see:\nSample Size 50: There is considerable variability around the true difference, indicating that smaller sample sizes can produce estimates that fluctuate widely.\nSample Size 200: The histogram becomes tighter around the true difference, with less variability than the sample size of 50.\nSample Size 500: Further reduction in variability is observed, and the distribution of averages is centered closely around the true difference.\nSample Size 1000: This histogram shows the least variability, and the average differences are clustering tightly around the true difference, with the center of the distribution aligning closely with the red line.\nLaw of Large Numbers: As the sample size increases, the cumulative average difference becomes more consistent and stable around the true difference. This is a demonstration of the Law of Large Numbers—the sample averages converge to the expected value as the sample size grows.\nCentral Limit Theorem: As the sample size increases, the distribution of sample means (average differences in this case) becomes more symmetrical and bell-shaped, which is evidence of the Central Limit Theorem in action. The sample means for larger sample sizes tend to form a normal distribution centered around the true population mean.\nZero in the Distribution: In all histograms, the zero mark is not in the middle of the distribution; it’s in the left tail. This is because the treatment group has a higher probability of donating than the control group (0.022 vs. 0.018), so the true difference is expected to be positive (0.004), not zero."
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\nCode\ndata = pd.read_csv('blueprinty.csv')\ndata = data.drop('Unnamed: 0', axis=1)\ndata\n\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n...\n...\n...\n...\n...\n\n\n1495\n2\nNortheast\n18.5\n1\n\n\n1496\n3\nSouthwest\n22.5\n0\n\n\n1497\n4\nSouthwest\n17.0\n0\n\n\n1498\n3\nSouth\n29.0\n0\n\n\n1499\n1\nSouth\n39.0\n0\n\n\n\n\n1500 rows × 4 columns\n\n\n\n\nCompare histograms and means of number of patents by customer status:\n\n\nCode\nmean_patents = data.groupby('iscustomer')['patents'].mean()\nmean_patents\n\n\niscustomer\n0    3.623177\n1    4.091371\nName: patents, dtype: float64\n\n\nThis indicate that, on average, customers have a slightly higher number of patents than non-customers. This might suggest that customer are more engaged or invest more patentable innovations, though other factors could also influence these resutls.\n\n\nCode\n# Set up the figure with two subplots for better comparison\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))\n\n# Plot histogram for non-customers\nsns.histplot(data[data['iscustomer'] == 0]['patents'], ax=axes[0], color='blue', bins=30, kde=True)\naxes[0].set_title('Patent Distribution for Non-Customers')\naxes[0].set_xlabel('Number of Patents')\naxes[0].set_ylabel('Frequency')\n\n# Plot histogram for customers\nsns.histplot(data[data['iscustomer'] == 1]['patents'], ax=axes[1], color='orange', bins=30, kde=True)\naxes[1].set_title('Patent Distribution for Customers')\naxes[1].set_xlabel('Number of Patents')\naxes[1].set_ylabel('Frequency')\n\n# Display the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nBoth groups show a similar general shape in their distribution, but customers tend to have a slightly higher frequency at higher patent counts, which corroborates the earlier finding that customers on average have more patents.\nThe distribution for both groups is skewed towards lower numbers of patents, with most individuals holding fewer patents.\nThe skewness is slightly more pronounced for customers, which could indicate that while fewer customers might have patents, those who do are likely to have more of them.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nCode\n# Visualize the age distribution across regions by customer status\nplt.figure(figsize=(10, 5))\n\n# Boxplot to show age distribution\nsns.boxplot(x='region', y='age', hue='iscustomer', data=data, palette=['blue', 'orange'])\n\n# Adjust plot labels and title\nplt.title('Age Distribution by Region and Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Age')\nplt.legend(title='Is Customer', labels=['Not Customer', 'Customer'])\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Group by 'iscustomer' and 'region', and get counts and mean age for each group\nregion_customer_summary = data.groupby(['iscustomer', 'region']).agg(\n    count=('region', 'count'),\n    mean_age=('age', 'mean')\n).reset_index()\n\n# Pivot the table to reshape it\npivot_table = region_customer_summary.pivot_table(\n    index='region',\n    columns='iscustomer',\n    values=['count', 'mean_age'],\n    aggfunc='first'\n).reset_index()\n\n# Flatten the columns MultiIndex properly by converting all elements to string before joining\npivot_table.columns = [' '.join(map(str, col)).strip() for col in pivot_table.columns.values]\n\n# Reset index if needed\npivot_table.reset_index(inplace=True)\npivot_table\n\n\n\n\n\n\n\n\n\n\nindex\nregion\ncount 0\ncount 1\nmean_age 0\nmean_age 1\n\n\n\n\n0\n0\nMidwest\n207\n17\n27.596618\n22.852941\n\n\n1\n1\nNortheast\n488\n113\n26.519467\n24.579646\n\n\n2\n2\nNorthwest\n171\n16\n26.532164\n20.812500\n\n\n3\n3\nSouth\n171\n20\n27.464912\n24.950000\n\n\n4\n4\nSouthwest\n266\n31\n25.907895\n24.500000\n\n\n\n\n\n\n\n\nCount and Customer Status:\nNon customer are more numerous across all regions compared to customers\nNorthleast has the highest count of non-customers, while Midwest has the lowest count of customers\nMean Age\nNon-customers tend to have a higher mean age in all regions compared to customers\nThe Northwest region has the youndest average for customer\nThis information suggests that there might be regional preferences or differences in how products and services are adopted between customer groups. Younger individual tend to be customers more in Northwest, indicating possible more innovate or youth-targeted offerings in that region.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe Likelihood Function is: \\[\nL(\\lambda) = \\prod_{i=1}^n \\frac{e^{\\lambda}\\lambda^{Y_i}}{Y_i!}\n\\]\nThis can also be expressed as: \\[\nL(\\lambda) = e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}.\n\\]\nThe log-likelihood function is: \\[\n\\log L(\\lambda) = -n\\lambda + \\log(\\lambda) \\sum_{i=1}^{n} Y_i - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\nDefine likelihood and log-likekihood function for the Poisson model\n\n\nCode\ndef poisson_likelihood(lam, Y):\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    likelihood = np.exp(-n * lam) * (lam ** sum_Y) / np.prod([np.math.factorial(y) for y in Y])\n    return likelihood\n\ndef poisson_log_likelihood(lam, Y):\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    log_likelihood = -n * lam + np.log(lam) * sum_Y - np.sum([np.log(np.math.factorial(y)) for y in Y])\n    return log_likelihood\n\n\nUse function to plot lambda\n\n\nCode\nimport warnings \nwarnings.filterwarnings(\"ignore\") \n\nY = data['patents']\n\n# Define the range for lambda values\nlambda_range = np.linspace(0.01, 10, 1000)  # Start from 0.01 to avoid log(0)\n\n# Calculate the log-likelihood for each lambda in the range\nlog_likelihood_values = [poisson_log_likelihood(lam, Y) for lam in lambda_range]\n\n# Plot the results\nplt.figure(figsize=(8, 3))\nplt.plot(lambda_range, log_likelihood_values, label='Log-Likelihood')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood of Observed Patent Counts Across Lambda Values')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nTo find the maximum likelihood estimator (MLE) for \\(\\lambda\\) , denoted as \\(\\lambda_{MLE}\\), we take the derivative of the log-likelihood with respect to \\(\\lambda\\) and set it equal to zero. The derivative is:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n\\]\nSetting this derivative equal to zero for maximization gives:\n\\[\n0 = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n\\]\nSimplifying and solving for ( ) yields:\n\\[\n\\lambda_{MLE} = \\bar{Y} = \\frac{1}{n}\\sum_{i=1}^{n} Y_i\n\\]\nSo the MLE of \\(\\lambda\\) is the sample mean \\(\\bar{Y}\\), which is intuitive since for a Poisson distribution, the mean and variance are both equal to \\(\\lambda\\).\n\n\nCode\nlambda_mle = Y.mean()\nprint('Maximum Likelihood Estimator is',{lambda_mle})\n\n\nMaximum Likelihood Estimator is {3.6846666666666668}\n\n\nFind the MLE by optimizing your likelihood function with scipy.optimize in Python.\n\n\nCode\nfrom scipy.optimize import minimize\n\n# We define the negative log-likelihood function for the Poisson distribution\ndef negative_poisson_log_likelihood(lam, Y):\n    if lam &lt;= 0:  # Avoid log(0) for lam=0\n        return np.inf\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    # The negative sign is important because we want to maximize the log-likelihood,\n    # which is equivalent to minimizing its negative.\n    neg_log_likelihood = n * lam - np.log(lam) * sum_Y + np.sum([np.log(np.math.factorial(y)) for y in Y])\n    return neg_log_likelihood\n\n# Initial guess for lambda can be the sample mean\ninitial_guess = [Y.mean()]\n\n# Minimize the negative log-likelihood function\nresult = minimize(\n    fun=negative_poisson_log_likelihood,\n    x0=initial_guess,\n    args=(Y,),\n    method='L-BFGS-B', # This optimization method allows for bounding the solution\n    bounds=[(1e-5, None)] # Lambda must be greater than 0\n)\n\n# Extract the MLE for lambda from the result\nlambda_mle = result.x[0] if result.success else None\nprint('Maximum Likelihood Estimator is',{lambda_mle})\n\n\nMaximum Likelihood Estimator is {3.6846666666666668}\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nThe Log-Likelihood function is:\n\\[\n\\log L(\\beta) = \\sum_{i=1}^{n} \\left( -e^{X_i' \\beta} + Y_i X_i' \\beta - \\log(Y_i!) \\right)\n\\]\n\n\nCode\n# Define Log-Likelihood function\ndef possion_regression_function(beta, Y, X):\n   # Calculate lambda for each observation\n    linear_predictor = X.dot(beta)\n\n    lambda_i = np.exp(linear_predictor)\n    \n    # Calculate the log-likelihood\n    log_likelihood = np.sum(-lambda_i + Y * np.log(lambda_i) - np.array([np.log(np.math.factorial(y)) for y in Y]))\n    \n    return log_likelihood\n\n\nUse the fuction to find the MLE vector and the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n\nCode\nfrom scipy.stats import poisson\nfrom numpy.linalg import inv\nfrom sklearn.preprocessing import StandardScaler\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age'] ** 2\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Select the numeric predictors\nnumeric_features = ['age', 'age_squared']\n\n# Fit and transform the features\ndata[numeric_features] = scaler.fit_transform(data[numeric_features])\n\nregions = pd.get_dummies(data['region'], drop_first=True)\n\nX = pd.concat([pd.Series(1, index=data.index, name='Intercept'), data[['age', 'age_squared', 'iscustomer']], regions], axis=1)\n\ndef convert_boolean_columns_to_int(df):\n    for column in df.columns:\n        if df[column].dtype == bool:\n            # Convert Boolean column to int\n            df[column] = df[column].astype(int)\n    return df\n\nX = convert_boolean_columns_to_int(X)\n\nX_column_names = X.columns\n\nY = data['patents']\n\nX_glm = X.copy()\nY_glm = Y.copy()\n\nX = X.values\nY = Y.values\n\n\ndef possion_neg_regression_function(beta, Y, X):\n    # Calculate lambda for each observation\n    linear_predictor = np.dot(X, beta)\n    lambda_i = np.exp(linear_predictor)\n    lambda_i = np.clip(lambda_i, 1e-10, np.inf)  \n\n    neg_log_likelihood = -np.sum(Y * np.log(lambda_i) - lambda_i)\n    return neg_log_likelihood\n\n# initial_beta = np.zeros(X.shape[1])\n# initial_beta = np.random.normal(loc=0, scale=1, size=X.shape[1])\ninitial_beta = np.zeros(X.shape[1])\ninitial_beta[0] = np.log(np.mean(Y))\n\n# Minimize the negative log-likelihood function\nresult = minimize(\n    fun=possion_neg_regression_function,\n    x0=initial_beta,\n    args=(Y, X),\n    method='L-BFGS-B',\n)\n\n\n\n\nCode\ndef hessian_neg_log_likelihood(beta, Y, X):\n    lambda_i = np.exp(np.dot(X, beta))\n    diag_lambda = np.diag(lambda_i)\n    hessian = np.dot(X.T, np.dot(diag_lambda, X))\n    return hessian\n\nhessian_matrix = hessian_neg_log_likelihood(result.x, Y, X)\n\ncovariance_matrix = inv(hessian_matrix)\n\nstandard_errors = np.sqrt(np.diag(covariance_matrix))\n\n# Display the coefficients and their standard errors\ncoefficients_table = pd.DataFrame({\n    'Coefficient': np.round(result.x, 4),\n    'Standard Error': np.round(standard_errors, 3)\n}, index=X_column_names)\nprint(coefficients_table)\n\n\n             Coefficient  Standard Error\nIntercept         1.2154           0.036\nage               1.0464           0.100\nage_squared      -1.1408           0.102\niscustomer        0.1181           0.039\nNortheast         0.0986           0.042\nNorthwest        -0.0201           0.054\nSouth             0.0572           0.053\nSouthwest         0.0514           0.047\n\n\nCheck results using sm.GLM() function.\n\n\nCode\nimport statsmodels.api as sm\n\nmodel = sm.GLM(Y_glm, X_glm, family=sm.families.Poisson())\nresults = model.fit()\n\n# Get the summary of the results\nglm_summary = results.summary()\n# Extract only the regression results table\nglm_results_table = glm_summary.tables[1]\n\n# To display or print out the table\nprint(glm_results_table)\n\n\n===============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept       1.2154      0.036     33.368      0.000       1.144       1.287\nage             1.0465      0.100     10.414      0.000       0.850       1.243\nage_squared    -1.1408      0.102    -11.131      0.000      -1.342      -0.940\niscustomer      0.1181      0.039      3.035      0.002       0.042       0.194\nNortheast       0.0986      0.042      2.347      0.019       0.016       0.181\nNorthwest      -0.0201      0.054     -0.374      0.709      -0.126       0.085\nSouth           0.0572      0.053      1.085      0.278      -0.046       0.160\nSouthwest       0.0513      0.047      1.088      0.277      -0.041       0.144\n===============================================================================\n\n\nInterpret the results:\n\nIntercept: This value represents the baseline log-odds of patent success when all other predictor variables are held at zero.\nage: For every one-year increase in age, the log-odds of patent success increase by 0.1445. This suggests a positive relationship between the age of the patent application (or applicant) and the likelihood of success.With p &lt; 0.001, this variable indicates a strong positive relationship with the outcome as age increases, up to a point (due to the quadratic term).\nage squared:The negative coefficient for age squared indicates a diminishing return effect; as age increases, its positive impact on patent success starts to decrease. This typically suggests a peak point beyond which additional years in age reduce the likelihood of success. Also with p &lt; 0.001, it confirms the non-linear relationship where increasing age has diminishing returns on the log odds of the outcome.\niscustomer: Being a customer is associated with an increase in the log-odds of patent success by 0.1181 compared to non-customers. This effect is statistically significant and suggests that customers of Blueprinty might have a higher likelihood of patent success. This variable is statistically significant (p = 0.002), showing that being a customer positively influences the outcome.\nRegional Effects:\n\n\nNortheast: Indicates a positive effect on patent success in the Northeast compared to the baseline region (the one dropped during dummy coding).\nNorthwest: Suggests a slight negative effect on patent success compared to the baseline, but this may not be statistically significant.\nSouth and Southwest: Both regions show a positive effect on patent success, though the effects are small and the confidence around these estimates might overlap with zero, suggesting limited statistical significance.\n\nConclusions:\n\nAge: There’s a clear positive relationship between age and patent success, which peaks and then starts to decline as indicated by the quadratic term (age squared). This could reflect that mid-career individuals or entities are most successful in patent applications, possibly due to optimal combinations of experience and active engagement in their fields.\nCustomer Status: Being a customer of Blueprinty has a positive impact on patent success. This suggests that the services or products provided by Blueprinty are effective in enhancing the success rate of patents for their customers.\nRegional Variations: There are some regional differences in patent success rates, with the Northeast and Southern regions showing a positive impact relative to the baseline region."
  },
  {
    "objectID": "projects/project2/index.html#blueprinty-case-study",
    "href": "projects/project2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\nCode\ndata = pd.read_csv('blueprinty.csv')\ndata = data.drop('Unnamed: 0', axis=1)\ndata\n\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n...\n...\n...\n...\n...\n\n\n1495\n2\nNortheast\n18.5\n1\n\n\n1496\n3\nSouthwest\n22.5\n0\n\n\n1497\n4\nSouthwest\n17.0\n0\n\n\n1498\n3\nSouth\n29.0\n0\n\n\n1499\n1\nSouth\n39.0\n0\n\n\n\n\n1500 rows × 4 columns\n\n\n\n\nCompare histograms and means of number of patents by customer status:\n\n\nCode\nmean_patents = data.groupby('iscustomer')['patents'].mean()\nmean_patents\n\n\niscustomer\n0    3.623177\n1    4.091371\nName: patents, dtype: float64\n\n\nThis indicate that, on average, customers have a slightly higher number of patents than non-customers. This might suggest that customer are more engaged or invest more patentable innovations, though other factors could also influence these resutls.\n\n\nCode\n# Set up the figure with two subplots for better comparison\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))\n\n# Plot histogram for non-customers\nsns.histplot(data[data['iscustomer'] == 0]['patents'], ax=axes[0], color='blue', bins=30, kde=True)\naxes[0].set_title('Patent Distribution for Non-Customers')\naxes[0].set_xlabel('Number of Patents')\naxes[0].set_ylabel('Frequency')\n\n# Plot histogram for customers\nsns.histplot(data[data['iscustomer'] == 1]['patents'], ax=axes[1], color='orange', bins=30, kde=True)\naxes[1].set_title('Patent Distribution for Customers')\naxes[1].set_xlabel('Number of Patents')\naxes[1].set_ylabel('Frequency')\n\n# Display the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nBoth groups show a similar general shape in their distribution, but customers tend to have a slightly higher frequency at higher patent counts, which corroborates the earlier finding that customers on average have more patents.\nThe distribution for both groups is skewed towards lower numbers of patents, with most individuals holding fewer patents.\nThe skewness is slightly more pronounced for customers, which could indicate that while fewer customers might have patents, those who do are likely to have more of them.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nCode\n# Visualize the age distribution across regions by customer status\nplt.figure(figsize=(10, 5))\n\n# Boxplot to show age distribution\nsns.boxplot(x='region', y='age', hue='iscustomer', data=data, palette=['blue', 'orange'])\n\n# Adjust plot labels and title\nplt.title('Age Distribution by Region and Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Age')\nplt.legend(title='Is Customer', labels=['Not Customer', 'Customer'])\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Group by 'iscustomer' and 'region', and get counts and mean age for each group\nregion_customer_summary = data.groupby(['iscustomer', 'region']).agg(\n    count=('region', 'count'),\n    mean_age=('age', 'mean')\n).reset_index()\n\n# Pivot the table to reshape it\npivot_table = region_customer_summary.pivot_table(\n    index='region',\n    columns='iscustomer',\n    values=['count', 'mean_age'],\n    aggfunc='first'\n).reset_index()\n\n# Flatten the columns MultiIndex properly by converting all elements to string before joining\npivot_table.columns = [' '.join(map(str, col)).strip() for col in pivot_table.columns.values]\n\n# Reset index if needed\npivot_table.reset_index(inplace=True)\npivot_table\n\n\n\n\n\n\n\n\n\n\nindex\nregion\ncount 0\ncount 1\nmean_age 0\nmean_age 1\n\n\n\n\n0\n0\nMidwest\n207\n17\n27.596618\n22.852941\n\n\n1\n1\nNortheast\n488\n113\n26.519467\n24.579646\n\n\n2\n2\nNorthwest\n171\n16\n26.532164\n20.812500\n\n\n3\n3\nSouth\n171\n20\n27.464912\n24.950000\n\n\n4\n4\nSouthwest\n266\n31\n25.907895\n24.500000\n\n\n\n\n\n\n\n\nCount and Customer Status:\nNon customer are more numerous across all regions compared to customers\nNorthleast has the highest count of non-customers, while Midwest has the lowest count of customers\nMean Age\nNon-customers tend to have a higher mean age in all regions compared to customers\nThe Northwest region has the youndest average for customer\nThis information suggests that there might be regional preferences or differences in how products and services are adopted between customer groups. Younger individual tend to be customers more in Northwest, indicating possible more innovate or youth-targeted offerings in that region.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe Likelihood Function is: \\[\nL(\\lambda) = \\prod_{i=1}^n \\frac{e^{\\lambda}\\lambda^{Y_i}}{Y_i!}\n\\]\nThis can also be expressed as: \\[\nL(\\lambda) = e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}.\n\\]\nThe log-likelihood function is: \\[\n\\log L(\\lambda) = -n\\lambda + \\log(\\lambda) \\sum_{i=1}^{n} Y_i - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\nDefine likelihood and log-likekihood function for the Poisson model\n\n\nCode\ndef poisson_likelihood(lam, Y):\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    likelihood = np.exp(-n * lam) * (lam ** sum_Y) / np.prod([np.math.factorial(y) for y in Y])\n    return likelihood\n\ndef poisson_log_likelihood(lam, Y):\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    log_likelihood = -n * lam + np.log(lam) * sum_Y - np.sum([np.log(np.math.factorial(y)) for y in Y])\n    return log_likelihood\n\n\nUse function to plot lambda\n\n\nCode\nimport warnings \nwarnings.filterwarnings(\"ignore\") \n\nY = data['patents']\n\n# Define the range for lambda values\nlambda_range = np.linspace(0.01, 10, 1000)  # Start from 0.01 to avoid log(0)\n\n# Calculate the log-likelihood for each lambda in the range\nlog_likelihood_values = [poisson_log_likelihood(lam, Y) for lam in lambda_range]\n\n# Plot the results\nplt.figure(figsize=(8, 3))\nplt.plot(lambda_range, log_likelihood_values, label='Log-Likelihood')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood of Observed Patent Counts Across Lambda Values')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nTo find the maximum likelihood estimator (MLE) for \\(\\lambda\\) , denoted as \\(\\lambda_{MLE}\\), we take the derivative of the log-likelihood with respect to \\(\\lambda\\) and set it equal to zero. The derivative is:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n\\]\nSetting this derivative equal to zero for maximization gives:\n\\[\n0 = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n\\]\nSimplifying and solving for ( ) yields:\n\\[\n\\lambda_{MLE} = \\bar{Y} = \\frac{1}{n}\\sum_{i=1}^{n} Y_i\n\\]\nSo the MLE of \\(\\lambda\\) is the sample mean \\(\\bar{Y}\\), which is intuitive since for a Poisson distribution, the mean and variance are both equal to \\(\\lambda\\).\n\n\nCode\nlambda_mle = Y.mean()\nprint('Maximum Likelihood Estimator is',{lambda_mle})\n\n\nMaximum Likelihood Estimator is {3.6846666666666668}\n\n\nFind the MLE by optimizing your likelihood function with scipy.optimize in Python.\n\n\nCode\nfrom scipy.optimize import minimize\n\n# We define the negative log-likelihood function for the Poisson distribution\ndef negative_poisson_log_likelihood(lam, Y):\n    if lam &lt;= 0:  # Avoid log(0) for lam=0\n        return np.inf\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    # The negative sign is important because we want to maximize the log-likelihood,\n    # which is equivalent to minimizing its negative.\n    neg_log_likelihood = n * lam - np.log(lam) * sum_Y + np.sum([np.log(np.math.factorial(y)) for y in Y])\n    return neg_log_likelihood\n\n# Initial guess for lambda can be the sample mean\ninitial_guess = [Y.mean()]\n\n# Minimize the negative log-likelihood function\nresult = minimize(\n    fun=negative_poisson_log_likelihood,\n    x0=initial_guess,\n    args=(Y,),\n    method='L-BFGS-B', # This optimization method allows for bounding the solution\n    bounds=[(1e-5, None)] # Lambda must be greater than 0\n)\n\n# Extract the MLE for lambda from the result\nlambda_mle = result.x[0] if result.success else None\nprint('Maximum Likelihood Estimator is',{lambda_mle})\n\n\nMaximum Likelihood Estimator is {3.6846666666666668}\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nThe Log-Likelihood function is:\n\\[\n\\log L(\\beta) = \\sum_{i=1}^{n} \\left( -e^{X_i' \\beta} + Y_i X_i' \\beta - \\log(Y_i!) \\right)\n\\]\n\n\nCode\n# Define Log-Likelihood function\ndef possion_regression_function(beta, Y, X):\n   # Calculate lambda for each observation\n    linear_predictor = X.dot(beta)\n\n    lambda_i = np.exp(linear_predictor)\n    \n    # Calculate the log-likelihood\n    log_likelihood = np.sum(-lambda_i + Y * np.log(lambda_i) - np.array([np.log(np.math.factorial(y)) for y in Y]))\n    \n    return log_likelihood\n\n\nUse the fuction to find the MLE vector and the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n\nCode\nfrom scipy.stats import poisson\nfrom numpy.linalg import inv\nfrom sklearn.preprocessing import StandardScaler\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age'] ** 2\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Select the numeric predictors\nnumeric_features = ['age', 'age_squared']\n\n# Fit and transform the features\ndata[numeric_features] = scaler.fit_transform(data[numeric_features])\n\nregions = pd.get_dummies(data['region'], drop_first=True)\n\nX = pd.concat([pd.Series(1, index=data.index, name='Intercept'), data[['age', 'age_squared', 'iscustomer']], regions], axis=1)\n\ndef convert_boolean_columns_to_int(df):\n    for column in df.columns:\n        if df[column].dtype == bool:\n            # Convert Boolean column to int\n            df[column] = df[column].astype(int)\n    return df\n\nX = convert_boolean_columns_to_int(X)\n\nX_column_names = X.columns\n\nY = data['patents']\n\nX_glm = X.copy()\nY_glm = Y.copy()\n\nX = X.values\nY = Y.values\n\n\ndef possion_neg_regression_function(beta, Y, X):\n    # Calculate lambda for each observation\n    linear_predictor = np.dot(X, beta)\n    lambda_i = np.exp(linear_predictor)\n    lambda_i = np.clip(lambda_i, 1e-10, np.inf)  \n\n    neg_log_likelihood = -np.sum(Y * np.log(lambda_i) - lambda_i)\n    return neg_log_likelihood\n\n# initial_beta = np.zeros(X.shape[1])\n# initial_beta = np.random.normal(loc=0, scale=1, size=X.shape[1])\ninitial_beta = np.zeros(X.shape[1])\ninitial_beta[0] = np.log(np.mean(Y))\n\n# Minimize the negative log-likelihood function\nresult = minimize(\n    fun=possion_neg_regression_function,\n    x0=initial_beta,\n    args=(Y, X),\n    method='L-BFGS-B',\n)\n\n\n\n\nCode\ndef hessian_neg_log_likelihood(beta, Y, X):\n    lambda_i = np.exp(np.dot(X, beta))\n    diag_lambda = np.diag(lambda_i)\n    hessian = np.dot(X.T, np.dot(diag_lambda, X))\n    return hessian\n\nhessian_matrix = hessian_neg_log_likelihood(result.x, Y, X)\n\ncovariance_matrix = inv(hessian_matrix)\n\nstandard_errors = np.sqrt(np.diag(covariance_matrix))\n\n# Display the coefficients and their standard errors\ncoefficients_table = pd.DataFrame({\n    'Coefficient': np.round(result.x, 4),\n    'Standard Error': np.round(standard_errors, 3)\n}, index=X_column_names)\nprint(coefficients_table)\n\n\n             Coefficient  Standard Error\nIntercept         1.2154           0.036\nage               1.0464           0.100\nage_squared      -1.1408           0.102\niscustomer        0.1181           0.039\nNortheast         0.0986           0.042\nNorthwest        -0.0201           0.054\nSouth             0.0572           0.053\nSouthwest         0.0514           0.047\n\n\nCheck results using sm.GLM() function.\n\n\nCode\nimport statsmodels.api as sm\n\nmodel = sm.GLM(Y_glm, X_glm, family=sm.families.Poisson())\nresults = model.fit()\n\n# Get the summary of the results\nglm_summary = results.summary()\n# Extract only the regression results table\nglm_results_table = glm_summary.tables[1]\n\n# To display or print out the table\nprint(glm_results_table)\n\n\n===============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept       1.2154      0.036     33.368      0.000       1.144       1.287\nage             1.0465      0.100     10.414      0.000       0.850       1.243\nage_squared    -1.1408      0.102    -11.131      0.000      -1.342      -0.940\niscustomer      0.1181      0.039      3.035      0.002       0.042       0.194\nNortheast       0.0986      0.042      2.347      0.019       0.016       0.181\nNorthwest      -0.0201      0.054     -0.374      0.709      -0.126       0.085\nSouth           0.0572      0.053      1.085      0.278      -0.046       0.160\nSouthwest       0.0513      0.047      1.088      0.277      -0.041       0.144\n===============================================================================\n\n\nInterpret the results:\n\nIntercept: This value represents the baseline log-odds of patent success when all other predictor variables are held at zero.\nage: For every one-year increase in age, the log-odds of patent success increase by 0.1445. This suggests a positive relationship between the age of the patent application (or applicant) and the likelihood of success.With p &lt; 0.001, this variable indicates a strong positive relationship with the outcome as age increases, up to a point (due to the quadratic term).\nage squared:The negative coefficient for age squared indicates a diminishing return effect; as age increases, its positive impact on patent success starts to decrease. This typically suggests a peak point beyond which additional years in age reduce the likelihood of success. Also with p &lt; 0.001, it confirms the non-linear relationship where increasing age has diminishing returns on the log odds of the outcome.\niscustomer: Being a customer is associated with an increase in the log-odds of patent success by 0.1181 compared to non-customers. This effect is statistically significant and suggests that customers of Blueprinty might have a higher likelihood of patent success. This variable is statistically significant (p = 0.002), showing that being a customer positively influences the outcome.\nRegional Effects:\n\n\nNortheast: Indicates a positive effect on patent success in the Northeast compared to the baseline region (the one dropped during dummy coding).\nNorthwest: Suggests a slight negative effect on patent success compared to the baseline, but this may not be statistically significant.\nSouth and Southwest: Both regions show a positive effect on patent success, though the effects are small and the confidence around these estimates might overlap with zero, suggesting limited statistical significance.\n\nConclusions:\n\nAge: There’s a clear positive relationship between age and patent success, which peaks and then starts to decline as indicated by the quadratic term (age squared). This could reflect that mid-career individuals or entities are most successful in patent applications, possibly due to optimal combinations of experience and active engagement in their fields.\nCustomer Status: Being a customer of Blueprinty has a positive impact on patent success. This suggests that the services or products provided by Blueprinty are effective in enhancing the success rate of patents for their customers.\nRegional Variations: There are some regional differences in patent success rates, with the Northeast and Southern regions showing a positive impact relative to the baseline region."
  },
  {
    "objectID": "projects/project2/index.html#airbnb-case-study",
    "href": "projects/project2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\nBasics exploratory data analysis\n\n\nCode\nairbnb = pd.read_csv('airbnb.csv')\nairbnb = airbnb.drop('Unnamed: 0', axis=1)\nairbnb.head()\n\n\n\n\n\n\n\n\n\n\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\nSummary statistics for numerical variables\n\n\nCode\nnumerical_summary = airbnb.describe()\nnumerical_summary\n\n\n\n\n\n\n\n\n\n\nid\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\n\n\n\n\ncount\n4.062800e+04\n40628.000000\n40468.000000\n40552.000000\n40628.000000\n40628.000000\n30433.000000\n30374.000000\n30372.000000\n\n\nmean\n9.698889e+06\n1102.368219\n1.124592\n1.147046\n144.760732\n15.904426\n9.198370\n9.413544\n9.331522\n\n\nstd\n5.460166e+06\n1383.269358\n0.385884\n0.691746\n210.657597\n29.246009\n1.119935\n0.844949\n0.902966\n\n\nmin\n2.515000e+03\n1.000000\n0.000000\n0.000000\n10.000000\n0.000000\n2.000000\n2.000000\n2.000000\n\n\n25%\n4.889868e+06\n542.000000\n1.000000\n1.000000\n70.000000\n1.000000\n9.000000\n9.000000\n9.000000\n\n\n50%\n9.862878e+06\n996.000000\n1.000000\n1.000000\n100.000000\n4.000000\n10.000000\n10.000000\n10.000000\n\n\n75%\n1.466789e+07\n1535.000000\n1.000000\n1.000000\n170.000000\n17.000000\n10.000000\n10.000000\n10.000000\n\n\nmax\n1.800967e+07\n42828.000000\n8.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\n\n\n\n\n\n\n\n\nCount of missing values for each column\n\n\nCode\nmissing_values = airbnb.isnull().sum()\nmissing_values\n\n\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\nHere’s what we’ve learned from the dataset:\nMissing Values:\nbathrooms: 160 missing values.\nbedrooms: 76 missing values.\nreview_scores_cleanliness, review_scores_location,review_scores_value: Over 10,000 missing values each. This represents about 25% of the data, which is significant.\nhost_since: 35 missing values.\nLet’s start by handling the missing values based on the strategy described. We will impute the missing values for bathrooms and bedrooms with the median and decide on the review scores next\nImpute missing values for ‘bathrooms’ and ‘bedrooms’ with their respective medians\n\n\nCode\nairbnb['bathrooms'].fillna(airbnb['bathrooms'].median(), inplace=True)\nairbnb['bedrooms'].fillna(airbnb['bedrooms'].median(), inplace=True)\n# Checking updated missing values status\nupdated_missing_values = airbnb.isnull().sum()\nupdated_missing_values\n\n\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                        0\nbedrooms                         0\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\nReview Scores: Given the high proportion of missing data (around 25%), filling them with the median or mean could introduce bias, especially if the missingness is not random. An alternative approach is to create a binary indicator variable for each of these scores, which will indicate whether the score was originally missing. This way, we retain all listings in our analysis and potentially capture some information about why scores might be missing (e.g., newer listings might not have scores yet).\nImpute missing review scores with the median\n\n\nCode\n# Create binary indicators for missing review scores\nairbnb['cleanliness_missing'] = airbnb['review_scores_cleanliness'].isnull().astype(int)\nairbnb['location_missing'] = airbnb['review_scores_location'].isnull().astype(int)\nairbnb['value_missing'] = airbnb['review_scores_value'].isnull().astype(int)\n\n# Impute missing review scores with the median\nairbnb['review_scores_cleanliness'].fillna(airbnb['review_scores_cleanliness'].median(), inplace=True)\nairbnb['review_scores_location'].fillna(airbnb['review_scores_location'].median(), inplace=True)\nairbnb['review_scores_value'].fillna(airbnb['review_scores_value'].median(), inplace=True)\n\n# Check if all missing values are addressed\nfinal_missing_values_check = airbnb.isnull().sum()\nfinal_missing_values_check\n\n\nid                            0\ndays                          0\nlast_scraped                  0\nhost_since                   35\nroom_type                     0\nbathrooms                     0\nbedrooms                      0\nprice                         0\nnumber_of_reviews             0\nreview_scores_cleanliness     0\nreview_scores_location        0\nreview_scores_value           0\ninstant_bookable              0\ncleanliness_missing           0\nlocation_missing              0\nvalue_missing                 0\ndtype: int64\n\n\nAll the missing values in the review scores have been addressed, and we now have binary indicators for whether the original scores were missing. The host_since column still has 35 missing values, but since it is not directly used in our model, we won’t focus on imputing it right now.\n\n\nCode\n# Setting up the visualization style\nsns.set(style=\"whitegrid\")\n\n# Plotting the distribution of number of reviews\nplt.figure(figsize=(8, 4))\nsns.histplot(airbnb['number_of_reviews'], bins=50, kde=True)\nplt.title('Distribution of Number of Reviews')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\n\nLet’s take a closer eye on 80% population of data\n\n\nCode\n# Calculate the 80th percentile\npercentile_80 = airbnb['number_of_reviews'].quantile(0.8)\n\n# Plotting the distribution of number of reviews limited to the 80th percentile\nplt.figure(figsize=(8, 4))\nsns.histplot(airbnb['number_of_reviews'], bins=50, kde=True, binrange=(0, percentile_80))\nplt.title('Distribution of Number of Reviews (80% of Data)')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Frequency')\nplt.xlim(0, percentile_80)\nplt.show()\n\n\n\n\n\n\n\n\n\nThe distribution of the number of reviews is highly skewed to the right, with most listings having a relatively low number of reviews and a few listings having a very high number\n\n\nCode\n# Visualization of number of reviews by room type\nplt.figure(figsize=(8, 4))\nsns.boxplot(x='room_type', y='number_of_reviews', data=airbnb)\nplt.title('Number of Reviews by Room Type')\nplt.xlabel('Room Type')\nplt.ylabel('Number of Reviews')\nplt.show()\n\n# Scatter plot for number of reviews vs. price\nplt.figure(figsize=(8, 4))\nsns.scatterplot(x='price', y='number_of_reviews', data=airbnb)\nplt.title('Number of Reviews vs. Price')\nplt.xlabel('Price')\nplt.ylabel('Number of Reviews')\nplt.xscale('log')  # Using logarithmic scale due to wide range of prices\nplt.show()\n\n# Scatter plots for number of reviews vs. review scores\nfig, axes = plt.subplots(1, 3, figsize=(8, 4))\nscore_vars = ['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']\ntitles = ['Cleanliness', 'Location', 'Value']\n\nfor ax, var, title in zip(axes, score_vars, titles):\n    sns.scatterplot(ax=ax, x=airbnb[var], y=airbnb['number_of_reviews'])\n    ax.set_title(f'Number of Reviews vs. {title}')\n    ax.set_xlabel(title)\n    ax.set_ylabel('Number of Reviews')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot interpretation:\nRoom Type:\nThe number of reviews varies by room type, with entire homes/apartments generally receiving more reviews than private or shared rooms. This might reflect a preference or higher turnover in these types of listings.\nPrice:\nThe relationship between price and number of reviews is not linear, suggesting that very high or very low priced listings might have fewer reviews. The logarithmic scale on price helps in visualizing this across a wide range of values.\nReview Scores:\nThere isn’t a clear trend in the scatter plots between review scores and the number of reviews, indicating that while scores may affect guest satisfaction, they do not necessarily correlate directly with the frequency of bookings (as measured by reviews). There might be a slight increase in reviews with higher scores for cleanliness and value.\n\n\nBuild Poisson Regression Model\n\n\nCode\nfrom patsy import dmatrices\n# Convert variables to the same time interval\n\nairbnb['last_scraped'] = pd.to_datetime(airbnb['last_scraped'])\nairbnb['host_since'] = pd.to_datetime(airbnb['host_since'])\n\n# Calculate the duration in years that each listing has been active\nairbnb['duration_years'] = (airbnb['last_scraped'] - airbnb['host_since']).dt.days / 365.25\n\n# Compute reviews per year\nairbnb['reviews_per_year'] = airbnb['number_of_reviews'] / airbnb['duration_years']\n\n# Handle cases where duration_years is zero to avoid division by zero\nairbnb['reviews_per_year'].fillna(0, inplace=True)\n\n\n# Encoding categorical variables using patsy (for statsmodels compatibility)\nformula = \"\"\"reviews_per_year ~ room_type + bathrooms + bedrooms + price +\n             review_scores_cleanliness + review_scores_location +\n             review_scores_value + cleanliness_missing + location_missing + value_missing\"\"\"\n\n# Prepare the design matrices for regression\ny, X = dmatrices(formula, airbnb, return_type='dataframe')\n\n# Fit a Poisson regression model using the same training data\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\npoisson_summary = poisson_results.summary()\n\n# Extract only the regression results table\npoisson_results_table = poisson_summary.tables[1]\n\n# To display or print out the table\nprint(poisson_results_table)\n\n\n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nIntercept                     2.1560      0.026     84.372      0.000       2.106       2.206\nroom_type[T.Private room]     0.0338      0.004      7.737      0.000       0.025       0.042\nroom_type[T.Shared room]      0.0871      0.012      7.525      0.000       0.064       0.110\nbathrooms                     0.0105      0.006      1.903      0.057      -0.000       0.021\nbedrooms                      0.0811      0.003     25.960      0.000       0.075       0.087\nprice                        -0.0002   1.86e-05    -12.370      0.000      -0.000      -0.000\nreview_scores_cleanliness     0.1249      0.002     53.488      0.000       0.120       0.129\nreview_scores_location       -0.0711      0.003    -28.236      0.000      -0.076      -0.066\nreview_scores_value          -0.0577      0.003    -20.285      0.000      -0.063      -0.052\ncleanliness_missing          -2.2750      0.122    -18.625      0.000      -2.514      -2.036\nlocation_missing             -1.1305      0.148     -7.651      0.000      -1.420      -0.841\nvalue_missing                -1.4111      0.145     -9.734      0.000      -1.695      -1.127\n=============================================================================================\n\n\n\n\nBuild Binomial Regression Model\n\n\nCode\n# # Encoding categorical variables using patsy (for statsmodels compatibility)\n# formula = \"\"\"number_of_reviews ~ room_type + bathrooms + bedrooms + price +\n#              review_scores_cleanliness + review_scores_location +\n#              review_scores_value + cleanliness_missing + location_missing + value_missing\"\"\"\n\n# Fit the negative binomial regression model\nnb_model = sm.GLM(y, X, family=sm.families.NegativeBinomial())\nnb_results = nb_model.fit()\n\n# Obtain the summary of the model\nnb_summary = nb_results.summary()\n\n# Extract only the regression results table\nnb_results_table = nb_summary.tables[1]\n\n# Display or print out the table\nprint(nb_results_table)\n\n\n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nIntercept                     2.3226      0.081     28.540      0.000       2.163       2.482\nroom_type[T.Private room]     0.0337      0.013      2.573      0.010       0.008       0.059\nroom_type[T.Shared room]      0.0954      0.037      2.588      0.010       0.023       0.168\nbathrooms                     0.0106      0.017      0.611      0.541      -0.023       0.045\nbedrooms                      0.0762      0.010      7.796      0.000       0.057       0.095\nprice                        -0.0002   4.12e-05     -4.826      0.000      -0.000      -0.000\nreview_scores_cleanliness     0.1825      0.007     26.014      0.000       0.169       0.196\nreview_scores_location       -0.0949      0.008    -11.657      0.000      -0.111      -0.079\nreview_scores_value          -0.1087      0.009    -11.981      0.000      -0.126      -0.091\ncleanliness_missing          -2.5131      0.165    -15.223      0.000      -2.837      -2.190\nlocation_missing             -0.6405      0.260     -2.466      0.014      -1.150      -0.131\nvalue_missing                -1.6547      0.258     -6.421      0.000      -2.160      -1.150\n=============================================================================================\n\n\nCoeficient Interpret for both model:\n\nIntercep: This is log of expected count of reviews when all other variables are zero. Since this scenario isn’t realistic, it primarily serves as baseline for the model\nroom_type\n\n\nPrivate room: listings that are private rooms have slightly more reviews compared to entire homes/apartments, holding other factors constant. The effect is relatively small\nShare room: Shared rooms are expected to have more reviews than the baseline category. Shared rooms show a stronger positive association with the number of reviews compared to private rooms.\n\n\nbathrooms: More bathrooms are associated with more reviews, indicating that listings with more bathrooms might be more frequently booked or reviewed.\nbedrooms: More bedrooms are associated with an increase in the expected count of reviews, suggesting that larger properties might attract more bookings and thus more reviews\nprice: A higher price is slightly negatively associated with the number of reviews. This small coeficient suggests that price inceases might slightly reduce the likelihood of getting reviewed.\nReview scores:\n\n\ncleanliness: higher clealiness scrores are positively associated with more reviews, indicating that cleanser listings are more likely to receive reviews.\nlocation: Surprisingly, better location scores are associated with fewer reviews. This might reflex a complex interaction with other factors not captured in the model or the properties in desiable locations might not meet all guest expectations or that guests in such locations review less frequently.\nvalue: Better value scores are also negatively associated with the number of reviews, which might suggest that guest have higher expectations that aren’t met as often they rate the value highly.\n\n\nMissing Indicators:\n\n\ncleanliness missing: Listing missing cleanliness scores have significantly fewer reviews, possibly indicating newer or less popular listings.\nlocation missing: Similarly, listings missing location scores have fewer reviews\nvalue missing: Listing missing value scores also have fewer reviews."
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "Visualization for all projects",
    "section": "",
    "text": "AB testing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "visualization/Possion/index.html",
    "href": "visualization/Possion/index.html",
    "title": "Poisson Regression Model",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport pyrsm as rsm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "visualization/Possion/index.html#column",
    "href": "visualization/Possion/index.html#column",
    "title": "Poisson Regression Model",
    "section": "Column",
    "text": "Column\n\nTab 1\n\nRow\nAirbnb Case Study\n\nColumn\n\n\nCode\nairbnb = pd.read_csv('/Users/duyentran/Desktop/UCSD_Study/MGTA495-MA/quarto_website/projects/project2/airbnb.csv')\n\nairbnb = airbnb.drop('Unnamed: 0', axis=1)\nairbnb['bathrooms'].fillna(airbnb['bathrooms'].median(), inplace=True)\nairbnb['bedrooms'].fillna(airbnb['bedrooms'].median(), inplace=True)\nairbnb['cleanliness_missing'] = airbnb['review_scores_cleanliness'].isnull().astype(int)\nairbnb['location_missing'] = airbnb['review_scores_location'].isnull().astype(int)\nairbnb['value_missing'] = airbnb['review_scores_value'].isnull().astype(int)\n\n# Impute missing review scores with the median\nairbnb['review_scores_cleanliness'].fillna(airbnb['review_scores_cleanliness'].median(), inplace=True)\nairbnb['review_scores_location'].fillna(airbnb['review_scores_location'].median(), inplace=True)\nairbnb['review_scores_value'].fillna(airbnb['review_scores_value'].median(), inplace=True)\n\n# Setting up the visualization style\nsns.set(style=\"whitegrid\")\n\n# Plotting the distribution of number of reviews\nplt.figure(figsize=(8, 4))\nsns.histplot(airbnb['number_of_reviews'], bins=50, kde=True)\n_ =plt.title('Distribution of Number of Reviews')\n_ =plt.xlabel('Number of Reviews')\n_ =plt.ylabel('Frequency')\nplt.show()\n\n\n/var/folders/28/cfl1_cfs3bb536qkz8wkys_w0000gn/T/ipykernel_19275/1262413431.py:4: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/28/cfl1_cfs3bb536qkz8wkys_w0000gn/T/ipykernel_19275/1262413431.py:5: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/28/cfl1_cfs3bb536qkz8wkys_w0000gn/T/ipykernel_19275/1262413431.py:11: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/28/cfl1_cfs3bb536qkz8wkys_w0000gn/T/ipykernel_19275/1262413431.py:12: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/28/cfl1_cfs3bb536qkz8wkys_w0000gn/T/ipykernel_19275/1262413431.py:13: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Calculate the 80th percentile\npercentile_80 = airbnb['number_of_reviews'].quantile(0.8)\n\n# Plotting the distribution of number of reviews limited to the 80th percentile\nplt.figure(figsize=(8, 4))\nsns.histplot(airbnb['number_of_reviews'], bins=50, kde=True, binrange=(0, percentile_80))\n_ =plt.title('Distribution of Number of Reviews (80% of Data)')\n_ =plt.xlabel('Number of Reviews')\n_ =plt.ylabel('Frequency')\nplt.xlim(0, percentile_80)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nColumn\n\n\nCode\n# Visualization of number of reviews by room type\nplt.figure(figsize=(8, 4))\nsns.boxplot(x='room_type', y='number_of_reviews', data=airbnb)\n_ =plt.title('Number of Reviews by Room Type')\n_ =plt.xlabel('Room Type')\n_ =plt.ylabel('Number of Reviews')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Scatter plot for number of reviews vs. price\nplt.figure(figsize=(8, 4))\nsns.scatterplot(x='price', y='number_of_reviews', data=airbnb)\n_ =plt.title('Number of Reviews vs. Price')\n_ =plt.xlabel('Price')\n_ =plt.ylabel('Number of Reviews')\nplt.xscale('log')  # Using logarithmic scale due to wide range of prices\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nColumn\n\n\nCode\n# Scatter plots for number of reviews vs. review scores\nfig, axes = plt.subplots(1, 3, figsize=(8, 4))\nscore_vars = ['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']\ntitles = ['Cleanliness', 'Location', 'Value']\n\nfor ax, var, title in zip(axes, score_vars, titles):\n    sns.scatterplot(ax=ax, x=airbnb[var], y=airbnb['number_of_reviews'])\n    _ =ax.set_title(f'Number of Reviews vs. {title}')\n    _ =ax.set_xlabel(title)\n    _ =ax.set_ylabel('Number of Reviews')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nTab 2\n\nRow\nBlueprinty Case Study\n\n\nRow\n\nColumn\n\n\nCode\ndata = pd.read_csv('/Users/duyentran/Desktop/UCSD_Study/MGTA495-MA/quarto_website/projects/project2/blueprinty.csv')\ndata = data.drop('Unnamed: 0', axis=1)\n\n\n\n\nCode\n# Set up the figure with two subplots for better comparison\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))\n\n# Plot histogram for non-customers\nsns.histplot(data[data['iscustomer'] == 0]['patents'], ax=axes[0], color='blue', bins=30, kde=True)\n_ = axes[0].set_title('Patent Distribution for Non-Customers')\n_ = axes[0].set_xlabel('Number of Patents')\n_ = axes[0].set_ylabel('Frequency')\n\n# Plot histogram for customers\nsns.histplot(data[data['iscustomer'] == 1]['patents'], ax=axes[1], color='orange', bins=30, kde=True)\n_ = axes[1].set_title('Patent Distribution for Customers')\n_ = axes[1].set_xlabel('Number of Patents')\n_ = axes[1].set_ylabel('Frequency')\n\n# Display the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nRow\n\nColumn\n\n\nCode\nplt.figure(figsize=(10, 5))\n\n# Boxplot to show age distribution\nsns.boxplot(x='region', y='age', hue='iscustomer', data=data, palette=['blue', 'orange'])\n\n# Adjust plot labels and title\n_ = plt.title('Age Distribution by Region and Customer Status')\n_ = plt.xlabel('Region')\n_ = plt.ylabel('Age')\nplt.legend(title='Is Customer', labels=['Not Customer', 'Customer'])\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nRow\n\nColumn\n\n\nCode\nimport warnings \nwarnings.filterwarnings(\"ignore\") \n\ndef poisson_likelihood(lam, Y):\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    likelihood = np.exp(-n * lam) * (lam ** sum_Y) / np.prod([np.math.factorial(y) for y in Y])\n    return likelihood\n\ndef poisson_log_likelihood(lam, Y):\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    log_likelihood = -n * lam + np.log(lam) * sum_Y - np.sum([np.log(np.math.factorial(y)) for y in Y])\n    return log_likelihood\n\nY = data['patents']\n\n# Define the range for lambda values\nlambda_range = np.linspace(0.01, 10, 1000)  # Start from 0.01 to avoid log(0)\n\n# Calculate the log-likelihood for each lambda in the range\nlog_likelihood_values = [poisson_log_likelihood(lam, Y) for lam in lambda_range]\n\n# Plot the results\nplt.figure(figsize=(8, 3))\nplt.plot(lambda_range, log_likelihood_values, label='Log-Likelihood')\n_ =plt.xlabel('Lambda (λ)')\n_ =plt.ylabel('Log-Likelihood')\n_ =plt.title('Log-Likelihood of Observed Patent Counts Across Lambda Values')\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "visualization/A:Btesting/index.html",
    "href": "visualization/A:Btesting/index.html",
    "title": "AB testing",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport pyrsm as rsm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "visualization/A:Btesting/index.html#row",
    "href": "visualization/A:Btesting/index.html#row",
    "title": "AB testing",
    "section": "Row",
    "text": "Row\nThis is a replication project doing A/B testing"
  },
  {
    "objectID": "visualization/A:Btesting/index.html#row-1",
    "href": "visualization/A:Btesting/index.html#row-1",
    "title": "AB testing",
    "section": "Row",
    "text": "Row\n\n\nCode\ndata = pd.read_stata(\"/Users/duyentran/Desktop/UCSD_Study/MGTA495-MA/quarto_website/projects/project1/karlan_list_2007.dta\")\n\n# Prepare the plots for treatment and control groups who made donations\ndata_donated = data[data['amount'] &gt; 0]\n\ndonated_treatment = data_donated.loc[data_donated['treatment'] == 1,'amount']\ndonated_control = data_donated.loc[data_donated['treatment'] == 0,'amount']\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n\n# Plot for Treatment Group\n_ =axes[0].hist(donated_treatment, bins=30, color='blue', alpha=0.7)\naxes[0].axvline(donated_treatment.mean(), color='red', linestyle='dashed', linewidth=1)\n_ =axes[0].set_title('Treatment Group Donation Amounts')\n_ =axes[0].set_xlabel('Donation Amount')\n_ =axes[0].set_ylabel('Frequency')\n_ =axes[0].text(donated_treatment.mean(), max(axes[0].get_ylim()) * 0.5, f'Average: {donated_treatment.mean():.2f}', color='red')\n\n# Plot for Control Group\n_ =axes[1].hist(donated_control, bins=30, color='green', alpha=0.7)\n_ =axes[1].axvline(donated_control.mean(), color='red', linestyle='dashed', linewidth=1)\n_ =axes[1].set_title('Control Group Donation Amounts')\n_ =axes[1].set_xlabel('Donation Amount')\n_ =axes[1].set_ylabel('Frequency')\n_ =axes[1].text(donated_control.mean(), max(axes[1].get_ylim()) * 0.5, f'Average: {donated_control.mean():.2f}', color='red')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "visualization/A:Btesting/index.html#row-2",
    "href": "visualization/A:Btesting/index.html#row-2",
    "title": "AB testing",
    "section": "Row",
    "text": "Row\n\nColumn\n\n\nCode\ngave_treatment = data[data['treatment'] == 1]['gave'].mean()\ngave_control = data[data['treatment'] == 0]['gave'].mean()\n\nproportions = [gave_treatment, gave_control]\ngroup_labels = ['Treatment', 'Control']\n\n# Create the bar plot\nplt.bar(group_labels, proportions, color=['blue', 'orange'])\n\n# Add labels and title\n_ =plt.ylabel('Proportion who donated', fontsize = 15)\n_ =plt.title('Proportion of Donations by Group', fontsize = 15)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nColumn\n\n\nCode\n# Define probabilities for Bernoulli distributions\np_control = 0.018  # Probability for control group\np_treatment = 0.022  # Probability for treatment group\n\n# Simulate 100,000 draws for the control group\ncontrol_samples = np.random.binomial(1, p_control, 100000)\n\n# Simulate 10,000 draws for the treatment group\ntreatment_samples = np.random.binomial(1, p_treatment, 10000)\n\n# Calculate differences for each of the first 10,000 elements in the control sample (to match treatment sample size)\ndifferences = treatment_samples - control_samples[:10000]\n\n# Calculate cumulative averages of differences\ncumulative_averages = np.cumsum(differences) / (np.arange(10000) + 1)\n\n# Plot the cumulative averages of the differences\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_averages, label='Cumulative Average of Differences', color='blue')\nplt.axhline(y=(p_treatment - p_control), color='red', linestyle='dashed', label='True Difference (0.022 - 0.018)')\n_ =plt.xlabel('Number of Simulations', fontsize = 15)\n_ =plt.ylabel('Cumulative Average of Difference', fontsize = 15)\n_ =plt.title('Cumulative Average of Differences Between Treatment and Control (Simulation)', fontsize = 15)\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "visualization/A:Btesting/index.html#row-3",
    "href": "visualization/A:Btesting/index.html#row-3",
    "title": "AB testing",
    "section": "Row",
    "text": "Row\n\n\nCode\n# Define sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5), sharey=True)\n\n# Simulate the process and plot the histograms\nfor i, sample_size in enumerate(sample_sizes):\n    # Simulate drawing samples and calculating the means 1000 times\n    sample_means = np.array([np.mean(np.random.binomial(1, p_treatment, sample_size) - \n                                     np.random.binomial(1, p_control, sample_size)) \n                             for _ in range(1000)])\n    \n    # Plot the histogram\n    _ =axes[i].hist(sample_means, bins=30, orientation='horizontal', color='blue', alpha=0.6, edgecolor='black')\n    \n    # Calculate the mean and standard deviation for the normal distribution curve\n    mean_of_sample_means = np.mean(sample_means)\n    std_dev_of_sample_means = np.std(sample_means)\n\n    # Generate values for the normal distribution curve\n    curve_x = np.linspace(mean_of_sample_means - 3 * std_dev_of_sample_means, \n                          mean_of_sample_means + 3 * std_dev_of_sample_means, 100)\n    curve_y = (1 / (std_dev_of_sample_means * np.sqrt(2 * np.pi)) *\n               np.exp(-(curve_x - mean_of_sample_means) ** 2 / (2 * std_dev_of_sample_means ** 2)))\n    \n    # Scale the curve y to match the histogram scale\n    curve_y_scaled = curve_y * max(np.histogram(sample_means, bins=30)[0]) / max(curve_y)\n    \n    # Draw the normal distribution curve as a red line\n    _ =axes[i].plot(curve_y_scaled, curve_x, '-')\n\n    # Add a red dashed line at the true difference\n    _ =axes[i].axhline(y=0.004, color='red', linestyle='dashed', linewidth=2)\n\n    # Set titles and labels\n    _ =axes[i].set_title(f'Sample Size {sample_size}', fontsize = 15)\n    _ =axes[i].set_xlabel('Frequency' if i == len(sample_sizes) - 1 else '', fontsize = 15)  # Only add xlabel to the last subplot\n    _ =axes[i].set_ylabel('Average Difference' if i == 0 else '', fontsize = 15)  # Only add ylabel to the first subplot\n\n# Adjust layout for better fit\nplt.tight_layout()\n\n# Show the plot\nplt.show()"
  }
]