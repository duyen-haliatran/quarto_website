---
title: "Key Drivers Analysis"
author: "Duyen Tran"
date: today
---


This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.

```{python}
import pandas as pd
data = pd.read_csv('data_for_drivers_analysis.csv')
data
```

_todo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, "usefulness", Shapley values for a linear regression, Johnson's relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python._
# Pearson Correlations

```{python}
import numpy as np

# Selecting relevant columns for correlation
columns_of_interest = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']
correlation_matrix = data[columns_of_interest].corrwith(data['satisfaction'])

# Convert to percentage format
pearson_correlations = (correlation_matrix * 100).round(1).astype(str) + '%'
pearson_correlations

```

```{python}
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

# Extracting features and target
X = data[columns_of_interest]
y = data['satisfaction']

# Standardizing the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Fitting the linear regression model
model = LinearRegression()
model.fit(X_scaled, y)

# Obtaining standardized coefficients
coefficients = model.coef_

# Standardized coefficients as a DataFrame for better manipulation
coefficients_df = pd.DataFrame({
    'Perception': columns_of_interest,
    'Standardized Coefficient': coefficients
})

# Convert to percentage format
coefficients_df['Standardized Coefficient'] = (coefficients_df['Standardized Coefficient'] * 100).round(1).astype(str) + '%'
coefficients_df.set_index('Perception', inplace=True)

coefficients_df

```

```{python}
from sklearn.ensemble import RandomForestRegressor

# Initialize the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the model
rf_model.fit(X, y)

# Calculate feature importances
importances = rf_model.feature_importances_

# Store importances in a DataFrame
importances_df = pd.DataFrame({
    'Perception': columns_of_interest,
    'Mean Decrease in Gini Coefficient': importances
})

# Convert to percentage format
importances_df['Mean Decrease in Gini Coefficient'] = (importances_df['Mean Decrease in Gini Coefficient'] * 100).round(1).astype(str) + '%'
importances_df.set_index('Perception', inplace=True)

importances_df


```


_If you want a challenge, either (1) implement one or more of the measures yourself. "Usefulness" is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost._






